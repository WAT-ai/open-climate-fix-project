{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwp_path = \"../data/nwp/20220101.zarr\"\n",
    "pv_metadata_path = \"../data/pv/PV_PVOutput.org_Italy_PVOutput_Italy_systems_metadata.csv\"\n",
    "pv_timeseries_path = \"../data/pv/pv_italy_pv_time_series.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwp = xr.open_dataset(nwp_path, engine='zarr', chunks='auto')\n",
    "pv_metadata = pd.read_csv(pv_metadata_path)\n",
    "pv_timeseries = pd.read_csv(pv_timeseries_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_metadata.drop(columns=pv_metadata.columns[0], axis=1, inplace=True)\n",
    "pv_timeseries['timestamp'] = pd.to_datetime(pv_timeseries['timestamp'])\n",
    "pv_timeseries = pv_timeseries.rename(columns={'timestamp':'time'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting a Day of Data\n",
    "Our PV data spans many years, but the NWP data is large, so it is split into chunks of single days. For each day, we will extract only that day of data from the PV data so we can align them in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = nwp['time'][0].values\n",
    "end_time = nwp['time'][-1].values\n",
    "\n",
    "pv_day_data = pv_timeseries[\n",
    "        (pv_timeseries['time'] >= start_time) &\n",
    "        (pv_timeseries['time'] <= end_time)\n",
    "    ].sort_values(by='time', ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping lat/lon\n",
    "The NWP data has lat/lon available at 0.25 increments (ie: 12.00, 12.25, 12.50, ...). While the PV data has precise lat/lon coords for specific PV sites. These coordinates could look like (12.141, 15.533).\n",
    "\n",
    "We want to map the PV coords to the nearest NWP. We do that like this:\n",
    "```python\n",
    "round(coordinate * 4) / 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_metadata['latitude'] = round(pv_metadata['latitude'] * 4) /4\n",
    "pv_metadata['longitude'] = round(pv_metadata['longitude'] * 4) /4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining Data\n",
    "Let's join the data. The desired end goal is to have a table where each row contains the `system_id` of a PV site, a `time`, the PV site's metrics (`instantaneous_power_W`, `temperature_C` and `voltage`) and the NWP data at that time, latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwp_df = nwp.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwp_pv_data = pv_day_data.merge(\n",
    "        pv_metadata[['system_id', 'latitude', 'longitude']],\n",
    "        how='left',\n",
    "        on='system_id'\n",
    "    ).merge(\n",
    "        nwp_df,\n",
    "        how='left',\n",
    "        on=['time', 'latitude', 'longitude']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwp_pv_data.to_csv('preprocessed_data/nwp_pv_joined_jan1_2022.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating the Data\n",
    "We have preprocessed the same day of data with a different method. We will check if this new data is the same as the old one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwp_pv_data.sort_values(['system_id'], inplace=True, ignore_index=True)\n",
    "ground_truth = pd.read_csv(\"preprocessed_data/processed_pv_data_jan1_2023_new.csv\")\n",
    "ground_truth.sort_values(['system_id'], inplace=True, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
